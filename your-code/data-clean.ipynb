{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharks attack\n",
    "\n",
    "## 1.- Data cleaning\n",
    "\n",
    "           \n",
    "\n",
    "Let's begin importing the libraries necesary to conduct this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file with all the shark attack information is located in the shark-attack folder of the repo. We load the data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks = pd.read_csv(\"../shark-attack/attacks.csv\", index_col=0, encoding = \"ISO-8859-1\") #encoding = \"utf-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the database is organized using .head() and .info(). This will allow us to decide how to prepare the data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018.06.25</th>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.06.18</th>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.06.09</th>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.06.08</th>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.06.04</th>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date    Year        Type    Country             Area  \\\n",
       "Case Number                                                                \n",
       "2018.06.25   25-Jun-2018  2018.0     Boating        USA       California   \n",
       "2018.06.18   18-Jun-2018  2018.0  Unprovoked        USA          Georgia   \n",
       "2018.06.09   09-Jun-2018  2018.0     Invalid        USA           Hawaii   \n",
       "2018.06.08   08-Jun-2018  2018.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "2018.06.04   04-Jun-2018  2018.0    Provoked     MEXICO           Colima   \n",
       "\n",
       "                                   Location     Activity             Name  \\\n",
       "Case Number                                                                 \n",
       "2018.06.25      Oceanside, San Diego County     Paddling      Julie Wolfe   \n",
       "2018.06.18   St. Simon Island, Glynn County     Standing  Adyson McNeely    \n",
       "2018.06.09                     Habush, Oahu      Surfing      John Denges   \n",
       "2018.06.08               Arrawarra Headland      Surfing             male   \n",
       "2018.06.04                         La Ticla  Free diving   Gustavo Ramos    \n",
       "\n",
       "            Sex   Age  ...         Species           Investigator or Source  \\\n",
       "Case Number            ...                                                    \n",
       "2018.06.25     F   57  ...      White shark                R. Collier, GSAF   \n",
       "2018.06.18     F   11  ...              NaN  K.McMurray, TrackingSharks.com   \n",
       "2018.06.09     M   48  ...              NaN  K.McMurray, TrackingSharks.com   \n",
       "2018.06.08     M  NaN  ...        2 m shark                  B. Myatt, GSAF   \n",
       "2018.06.04     M  NaN  ...  Tiger shark, 3m                       A .Kipper   \n",
       "\n",
       "                                  pdf  \\\n",
       "Case Number                             \n",
       "2018.06.25       2018.06.25-Wolfe.pdf   \n",
       "2018.06.18     2018.06.18-McNeely.pdf   \n",
       "2018.06.09      2018.06.09-Denges.pdf   \n",
       "2018.06.08   2018.06.08-Arrawarra.pdf   \n",
       "2018.06.04       2018.06.04-Ramos.pdf   \n",
       "\n",
       "                                                  href formula  \\\n",
       "Case Number                                                      \n",
       "2018.06.25   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2018.06.18   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2018.06.09   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2018.06.08   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2018.06.04   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                          href Case Number.1  \\\n",
       "Case Number                                                                    \n",
       "2018.06.25   http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "2018.06.18   http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2018.06.09   http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "2018.06.08   http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.08   \n",
       "2018.06.04   http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.04   \n",
       "\n",
       "            Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "Case Number                                                       \n",
       "2018.06.25     2018.06.25         6303.0         NaN         NaN  \n",
       "2018.06.18     2018.06.18         6302.0         NaN         NaN  \n",
       "2018.06.09     2018.06.09         6301.0         NaN         NaN  \n",
       "2018.06.08     2018.06.08         6300.0         NaN         NaN  \n",
       "2018.06.04     2018.06.04         6299.0         NaN         NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25723 entries, 2018.06.25 to xx\n",
      "Data columns (total 23 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Date                    6302 non-null   object \n",
      " 1   Year                    6300 non-null   float64\n",
      " 2   Type                    6298 non-null   object \n",
      " 3   Country                 6252 non-null   object \n",
      " 4   Area                    5847 non-null   object \n",
      " 5   Location                5762 non-null   object \n",
      " 6   Activity                5758 non-null   object \n",
      " 7   Name                    6092 non-null   object \n",
      " 8   Sex                     5737 non-null   object \n",
      " 9   Age                     3471 non-null   object \n",
      " 10  Injury                  6274 non-null   object \n",
      " 11  Fatal (Y/N)             5763 non-null   object \n",
      " 12  Time                    2948 non-null   object \n",
      " 13  Species                 3464 non-null   object \n",
      " 14  Investigator or Source  6285 non-null   object \n",
      " 15  pdf                     6302 non-null   object \n",
      " 16  href formula            6301 non-null   object \n",
      " 17  href                    6302 non-null   object \n",
      " 18  Case Number.1           6302 non-null   object \n",
      " 19  Case Number.2           6302 non-null   object \n",
      " 20  original order          6309 non-null   float64\n",
      " 21  Unnamed: 22             1 non-null      object \n",
      " 22  Unnamed: 23             2 non-null      object \n",
      "dtypes: float64(2), object(21)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "sharks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- Having a look at the column names, We will rename three of them, as for two of them (\"Sex \", \"Species \") there is an extra space at the end of the column name. The other, \"Fatal (Y/N)\", we will rename it as just \"Fatal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Year', 'Type', 'Country', 'Area', 'Location', 'Activity',\n",
       "       'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time', 'Species ',\n",
       "       'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
       "       'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks=sharks.rename(columns={\"Sex \": \"Sex\", \"Species \": \"Species\", \"Fatal (Y/N)\": \"Fatal\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Now we will drop the colums with almost all values NaN, that are 'Unnamed: 22' and 'Unnamed: 23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks=sharks.drop(columns=['Unnamed: 22', 'Unnamed: 23'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- There are as well columns with almost exact information ('Case Number.1'/'Case Number.2' and  'href formula'/'href'). So we eliminate one of each pair and rename the remaining one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks=sharks.rename(columns={\"Case Number.1\": \"Case Number\", \"href \": \"link\"})\n",
    "sharks=sharks.drop(columns=['href formula', 'Case Number.2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- From the date column, we extract the information of the month (the year is in another table, and we are not going to work with the exact day of the year). To do so, we use regex to find the month information in each column. For a fraction of them, this information is not available, so we mark them with \"Unk\" (unknown). \n",
    "\n",
    "The information with NaN is marked afterwards with \"Unk\" as well to fill these points in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_month(string):\n",
    "    months = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "    #If it founds the info of a month, it returns it as an output of this cleaning function\n",
    "    try:\n",
    "        for month in months:\n",
    "            if re.search(month,string):\n",
    "                return month\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "sharks['Month'] = sharks['Date']    \n",
    "sharks['Month'] = sharks['Date'].apply(find_month)\n",
    "sharks['Month'].fillna(value=\"Unk\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.- Now we are going to clean the \"Type\" column, so we group all boat related incidents in the \"Boating\" category. We also gropup all \"Questionable\" and \"Invalid\" categories into \"Unknown\", as well as the NaN data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Boating', 'Unprovoked', 'Invalid', 'Provoked', 'Questionable',\n",
       "       'Sea Disaster', nan, 'Boat', 'Boatomg'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharks[\"Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sharks['Type'].fillna(\"Unknown\",inplace=True)\n",
    "sharks['Type'] = sharks['Type'].apply(lambda x: \"Boating\" if x == \"Boat\" else x)\n",
    "sharks['Type'] = sharks['Type'].apply(lambda x: \"Boating\" if x == \"Boatomg\" else x)\n",
    "sharks['Type'] = sharks['Type'].apply(lambda x: \"Unknown\" if x == \"Questionable\" else x)\n",
    "sharks['Type'] = sharks['Type'].apply(lambda x: \"Unknown\" if x == \"Invalid\" else x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.- Now we reformat the information about the gender information in the database, as there are son extra spaces and wrong inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'M', nan, 'M ', 'lli', 'N', '.'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharks[\"Sex\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks['Sex'].fillna(\"UNKNOWN\",inplace=True) \n",
    "sharks['Sex'] = sharks['Sex'].apply(lambda x: \"M\" if x == \"M \" else x)\n",
    "#The rest of them as I checked I prefer to group them in the UNKNOWN category\n",
    "sharks['Sex'] = sharks['Sex'].apply(lambda x: \"UNKNOWN\" if x == \"N\" else x)\n",
    "sharks['Sex'] = sharks['Sex'].apply(lambda x: \"UNKNOWN\" if x == \"lli\" else x)\n",
    "sharks['Sex'] = sharks['Sex'].apply(lambda x: \"UNKNOWN\" if x == \".\" else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.- In the case of the \"Fatal\" column, we rename some values to group them in the same category. There are two inputs that, looking at the other columns, they are non fatal, so we mark them like thar. The NaN rows are filled with \"UNKNOWN\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y', nan, 'M', 'UNKNOWN', '2017', ' N', 'N ', 'y'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharks[\"Fatal\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks['Fatal'].fillna(\"UNKNOWN\",inplace=True) \n",
    "sharks['Fatal'] = sharks['Fatal'].apply(lambda x: \"N\" if x == \" N\" else x)\n",
    "sharks['Fatal'] = sharks['Fatal'].apply(lambda x: \"Y\" if x == \"y\" else x)\n",
    "#As they were only a few, I checked them\n",
    "sharks['Fatal'] = sharks['Fatal'].apply(lambda x: \"N\" if x == \"M\" else x)\n",
    "sharks['Fatal'] = sharks['Fatal'].apply(lambda x: \"N\" if x == \"2017\" else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.- In order to clean the country information, we are going to put homogeneity in the data by capitalizing all the inputs. We mark as \"UNKNOWN\" when a cell is between two countries, as we don't know with precision the country. The same applies when there is a question mark. We also group the \"COAST OF AFRICA\" values as \"AFRICA\". Lastly, all NaN are marked as \"UNKNOWN\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks['Country'].fillna(\"UNKNOWN\",inplace=True) \n",
    "sharks['Country'] = sharks['Country'].apply(lambda x: x.upper())\n",
    "sharks['Country'] = sharks['Country'].apply(lambda x: \"UNKNOWN\" if (\"/\" in list(x)) else x)\n",
    "sharks['Country'] = sharks['Country'].apply(lambda x: \"UNKNOWN\" if (\"?\" in list(x)) else x)\n",
    "sharks['Country'] = sharks['Country'].apply(lambda x: \"AFRICA\" if x==\"COAST OF AFRICA\" else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.- For the rest of columns (except the \"Species\" column, that we are going to treat in the following section), we fill NaN values with \"Unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks['Investigator or Source'].fillna(\"Unknown\",inplace=True)\n",
    "sharks['Area'].fillna(\"Unknown\",inplace=True) \n",
    "sharks['Location'].fillna(\"Unknown\",inplace=True) \n",
    "sharks['Time'].fillna(\"Unknown\",inplace=True) \n",
    "sharks['Name'].fillna(\"Unknown\",inplace=True) \n",
    "sharks['Age'].fillna(\"Unknown\",inplace=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.- Lastly, we are going to clean the \"Species\" columns. With the help of regex, we are going to replace the string of the description with the name of the species, if available. If not, we are going to mark it with \"Unknown\", just as the NaN values. In addition, there are inputs that shows that some events are not related with sharks attacks, or it i not confirmed, so we are going to lable them as \"Questionable\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_species(string):\n",
    "    #List with species appearing in the different columns\n",
    "    species = [\"wobbegong\",\"tiger\",\"bull\",\"grey\",\"nurse\",\"cookiecutter\",\"spinner\",\"white\",\"sandtiger\",\n",
    "               \"eeef\",\"bronze whaler\",\"galapagos\",\"blacktip\",\"hammerhead\",\"mako\",\"blue\",\"salmon\",\"porbeagle\",\n",
    "               \"raggedtooth\",\"zambesi\",\"whitetip\",\"lemon\",\"thresher\",\"sandtiger\",\"spurdog\",\"reef\"\n",
    "               ,\"bronze whale\",\"seven-gill\",\"sevengill\",\"angel\",\"goblin\",\"sandbar\",\"copper\",\"whaler\"\n",
    "               ,\"dusky\",\"leopard\",\"sand\",\"zambezi\",\"silky\",\"whale\",\"dog\",\"blackfin\",\"albimarginatus\"\n",
    "               ,\"carpet\",\"broadnose\",\"bonita\",\"scyliorhinus canicula\",\"cow\",\"cookie cutter\",\"smoothhound\"\n",
    "               ,\"basking\",\"catsharks\",\"hooked\",\"carcharhinid\",\"gaffed\",\"silvertip\"]\n",
    "    #Trigger strings to labble events as questionable\n",
    "    doubts = [\"hoax\",\"not confirmed\",\"invalid incident\",\"questionable\",\"not a shark\",\"doubtful\"\n",
    "            \"no shark\",\"not cofirmed\",\"unconfired\",\"unconfirmed\",\"could not be determined\",\"stunt\"]    \n",
    "    \n",
    "    #For loop to replace the string with the name of the shark species\n",
    "    for shark in species:\n",
    "        if re.search(shark,string.lower()):\n",
    "            return shark.capitalize()\n",
    "    \n",
    "    #For loop to lable the questionable incidents\n",
    "    for doubt in doubts:\n",
    "        if re.search(doubt,string.lower()):\n",
    "            return \"Questionable\"\n",
    "    \n",
    "    #If there is no clear information about the shark, return Unknown\n",
    "    return \"Unknown\"\n",
    "\n",
    "sharks['Species'].fillna(\"Unknown\",inplace=True) \n",
    "sharks['Species'] = sharks['Species'].apply(clean_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the questionable rows are only a few, we can drop them off the database without biasing our analysis, so we can obtain more reliable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharks[sharks['Species'] == \"Questionable\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks=sharks[sharks['Species'] != \"Questionable\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save the clean dataset into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks.to_csv(r'../shark-attack/attacks_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization and analysis of the cleaned dataset is detailed in the data-wrangling notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
